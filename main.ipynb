{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 32-bit",
   "display_name": "Python 3.8.5 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "4f7b4d158a2467b4e1383513dae02ccf8e5288ddbedae9374d36c481258c1702"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Configure spark session\n",
    "spark = SparkSession.builder.master('local[2]').appName('quake_etl')\\\n",
    "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:2.4.1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(Date='01/02/1965', Time='13:44:18', Latitude='19.246', Longitude='145.616', Type='Earthquake', Depth='131.6', Depth Error=None, Depth Seismic Stations=None, Magnitude='6', Magnitude Type='MW', Magnitude Error=None, Magnitude Seismic Stations=None, Azimuthal Gap=None, Horizontal Distance=None, Horizontal Error=None, Root Mean Square=None, ID='ISCGEM860706', Source='ISCGEM', Location Source='ISCGEM', Magnitude Source='ISCGEM', Status='Automatic')]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_load = spark.read.csv(r\"C:\\\\Users\\\\brian\\\\Downloads\\\\database.csv\", header=True)\n",
    "\n",
    "# Preview df_load\n",
    "df_load.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------+---------+----------+-----+---------+--------------+------------+\n|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|\n+----------+--------+---------+----------+-----+---------+--------------+------------+\n|01/02/1965|  19.246|  145.616|Earthquake|131.6|        6|            MW|ISCGEM860706|\n|01/04/1965|   1.863|  127.352|Earthquake|   80|      5.8|            MW|ISCGEM860737|\n|01/05/1965| -20.579| -173.972|Earthquake|   20|      6.2|            MW|ISCGEM860762|\n|01/08/1965| -59.076|  -23.557|Earthquake|   15|      5.8|            MW|ISCGEM860856|\n|01/09/1965|  11.938|  126.427|Earthquake|   15|      5.8|            MW|ISCGEM860890|\n+----------+--------+---------+----------+-----+---------+--------------+------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Drop fields we don't need from df_load\n",
    "lst_dropped_columns = ['Depth Error', 'Time', 'Depth Seismic Stations', 'Magnitude Error', 'Magnitude Seismic Stations', 'Azimuthal Gap', 'Horizontal Distance', 'Horizontal Error', 'Root Mean Square', 'Source', 'Location Source', 'Magnitude Source', 'Status']\n",
    "\n",
    "df_load = df_load.drop(*lst_dropped_columns)\n",
    "\n",
    "# Preview df_load\n",
    "df_load.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|Year|\n+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n|01/02/1965|  19.246|  145.616|Earthquake|131.6|        6|            MW|ISCGEM860706|1965|\n|01/04/1965|   1.863|  127.352|Earthquake|   80|      5.8|            MW|ISCGEM860737|1965|\n|01/05/1965| -20.579| -173.972|Earthquake|   20|      6.2|            MW|ISCGEM860762|1965|\n|01/08/1965| -59.076|  -23.557|Earthquake|   15|      5.8|            MW|ISCGEM860856|1965|\n|01/09/1965|  11.938|  126.427|Earthquake|   15|      5.8|            MW|ISCGEM860890|1965|\n+----------+--------+---------+----------+-----+---------+--------------+------------+----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Create a year field and add it to the dataframe\n",
    "df_load = df_load.withColumn('Year', year(to_timestamp('Date', 'dd/MM/yyyy')))\n",
    "\n",
    "# Preview df_load\n",
    "df_load.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+------+\n|Year|Counts|\n+----+------+\n|1990|   196|\n|1975|   150|\n|1977|   148|\n|2003|   187|\n|2007|   211|\n+----+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Build the quakes frequency dataframe using the year field and counts for each year\n",
    "df_quake_freq = df_load.groupBy('Year').count().withColumnRenamed('count', 'Counts')\n",
    "\n",
    "# Preview df_quake_freq\n",
    "df_quake_freq.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- Date: string (nullable = true)\n |-- Latitude: string (nullable = true)\n |-- Longitude: string (nullable = true)\n |-- Type: string (nullable = true)\n |-- Depth: string (nullable = true)\n |-- Magnitude: string (nullable = true)\n |-- Magnitude Type: string (nullable = true)\n |-- ID: string (nullable = true)\n |-- Year: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Preview df-load schema\n",
    "df_load.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|Year|\n+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n|01/02/1965|  19.246|  145.616|Earthquake|131.6|      6.0|            MW|ISCGEM860706|1965|\n|01/04/1965|   1.863|  127.352|Earthquake| 80.0|      5.8|            MW|ISCGEM860737|1965|\n|01/05/1965| -20.579| -173.972|Earthquake| 20.0|      6.2|            MW|ISCGEM860762|1965|\n|01/08/1965| -59.076|  -23.557|Earthquake| 15.0|      5.8|            MW|ISCGEM860856|1965|\n|01/09/1965|  11.938|  126.427|Earthquake| 15.0|      5.8|            MW|ISCGEM860890|1965|\n+----------+--------+---------+----------+-----+---------+--------------+------------+----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Cast some fields from string into numeric types\n",
    "df_load = df_load.withColumn('Latitude', df_load['Latitude'].cast(DoubleType()))\\\n",
    "    .withColumn('Longitude', df_load['Longitude'].cast(DoubleType()))\\\n",
    "    .withColumn('Depth', df_load['Depth'].cast(DoubleType()))\\\n",
    "    .withColumn('Magnitude', df_load['Magnitude'].cast(DoubleType()))\n",
    "\n",
    "# Preview df_load\n",
    "df_load.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- Date: string (nullable = true)\n |-- Latitude: double (nullable = true)\n |-- Longitude: double (nullable = true)\n |-- Type: string (nullable = true)\n |-- Depth: double (nullable = true)\n |-- Magnitude: double (nullable = true)\n |-- Magnitude Type: string (nullable = true)\n |-- ID: string (nullable = true)\n |-- Year: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Preview df_load schema\n",
    "df_load.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create average magnitude and maximum fields and add to df_quake_freq\n",
    "df_max = df_load.groupBy('Year').max('Magnitude').withColumnRenamed('max(Magnitude)', 'Max_Magnitude')\n",
    "df_avg = df_load.groupBy('Year').avg('Magnitude').withColumnRenamed('avg(Magnitude)', 'Avg_Magnitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+------+-----------------+-------------+\n|Year|Counts|    Avg_Magnitude|Max_Magnitude|\n+----+------+-----------------+-------------+\n|1990|   196|5.858163265306125|          7.6|\n|1975|   150| 5.84866666666667|          7.8|\n|1977|   148|5.757432432432437|          7.6|\n|2003|   187|5.850802139037435|          7.6|\n|2007|   211| 5.89099526066351|          8.4|\n+----+------+-----------------+-------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Join df_max and df_avg to df_quake_freq\n",
    "df_quake_freq = df_quake_freq.join(df_avg, ['Year']).join(df_max, ['Year'])\n",
    "\n",
    "# Preview df_quake_freq\n",
    "df_quake_freq.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[Year: int, Counts: bigint, Avg_Magnitude: double, Max_Magnitude: double]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Remove nulls\n",
    "df_load.dropna()\n",
    "df_quake_freq.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|Year|\n+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n|01/02/1965|  19.246|  145.616|Earthquake|131.6|      6.0|            MW|ISCGEM860706|1965|\n|01/04/1965|   1.863|  127.352|Earthquake| 80.0|      5.8|            MW|ISCGEM860737|1965|\n|01/05/1965| -20.579| -173.972|Earthquake| 20.0|      6.2|            MW|ISCGEM860762|1965|\n|01/08/1965| -59.076|  -23.557|Earthquake| 15.0|      5.8|            MW|ISCGEM860856|1965|\n|01/09/1965|  11.938|  126.427|Earthquake| 15.0|      5.8|            MW|ISCGEM860890|1965|\n+----------+--------+---------+----------+-----+---------+--------------+------------+----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Preview dataframes\n",
    "df_load.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+------+-----------------+-------------+\n|Year|Counts|    Avg_Magnitude|Max_Magnitude|\n+----+------+-----------------+-------------+\n|1990|   196|5.858163265306125|          7.6|\n|1975|   150| 5.84866666666667|          7.8|\n|1977|   148|5.757432432432437|          7.6|\n|2003|   187|5.850802139037435|          7.6|\n|2007|   211| 5.89099526066351|          8.4|\n+----+------+-----------------+-------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_quake_freq.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the tables/collections in MongoDB\n",
    "# Write df_load to MongoDB\n",
    "df_load.write.format('mongo')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('spark.mongodb.output.uri', 'mongodb://127.0.0.1:27017/Quake.quakes').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write df_quake_freq to MongoDB\n",
    "df_quake_freq.write.format('mongo')\\\n",
    "    .mode('overwrite')\\\n",
    "    .option('spark.mongodb.output.uri', 'mongodb://127.0.0.1:27017/Quake.quake_freq').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}